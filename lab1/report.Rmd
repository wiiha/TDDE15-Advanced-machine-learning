---
title: "TDDE15 - LAB 1"
author: "Wilhelm Hansson (wilha431)"
date: "2020-09-13"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(bnlearn)
library(Rgraphviz)
library(gRain)

source("./helper-functions.R")

data("asia")
```

# Task 1

*Show that multiple runs of the hill-climbing algorithm can return non-equivalent Bayesian network (BN) structures. Explain why this happens.*

```{r 1_1, include=FALSE}
# Testing different random restarts
nodes <- colnames(asia)
init <- empty.graph(nodes)
set.seed(567)
arc.set.1 = matrix(c("A", "S", "X", "D", "E", "X", "X", "T"),
                   ncol = 2, byrow = TRUE,
                   dimnames = list(NULL, c("from", "to")))
arcs(init) = arc.set.1
bn1 <- hc(x = asia, restart = 1, start=init, score = "bic")
cpdag.bn1 <- cpdag(bn1)

set.seed(567)
arc.set.2 = matrix(c("S", "A"),
                   ncol = 2, byrow = TRUE,
                   dimnames = list(NULL, c("from", "to")))
arcs(init) = arc.set.2
bn2 <- hc(x = asia, restart = 100, start=init, score = "mbde")
cpdag.bn2 <- cpdag(bn2)

```

```{r}
plot(cpdag.bn1, main="PDAG | 1 restart, scoring BIC")
```


```{r}
plot(cpdag.bn2, main="PDAG | 100 restart, scoring mbde")
```


```{r}
all.equal(cpdag.bn1,cpdag.bn2)
```

**Conclusion:** The chaining of scoring method seem to have largest impact when learning the structure of a BN. However, the number of random restarts also seem to contribute to the final BN. These findings align with the fact that the hill-climbing algorithm starts at a random point in graph space and the tries different graphs and evaluate the score for each of these graphs. By doing multiple restarts more of graph space is explored. A graph with many edges can be interpreted as an overfitted model. *BIC* solve this by implementing a penelty to the score based on number of edges. More info can be found in the paper by Koski and  Noble (2012).




# Task 2

*Learn a BN from 80 % of the Asia dataset. Use the BN learned to classify the remaining 20 % of the Asia dataset in two classes: S = yes and S = no. Use exact or approximate inference with the help of the bnlearn and gRain packages, you are not allowed to use functions such as predict. Report the confusion matrix; true/false positives/negatives.*

```{r 2_1, include=FALSE}
set.seed(2020)

# Splitting data 80/20 train/test
n=nrow(asia)
id=sample(1:n,floor(n*0.8))
train=asia[id,]
test=asia[-id,]

# Learning the structure of the BN.
bn.structure <- hc(x = train, restart = 15, score = "bic")
# Learning the parameters.
bn.fitted <- bn.fit(x = bn.structure, data = train, method = "bayes")

# Setting the true structure of the BN
bn.true.structure = model2network("[A][S][T|A][L|S][B|S][D|B:E][E|T:L][X|E]")
# Learning the parameters using the true structure.
bn.true.fitted <- bn.fit(x = bn.true.structure, data = train, method = "bayes")

# Converting to grain obj. to use in compile.grain.
bn.fitted.grain <- as.grain(bn.fitted)
bn.true.fitted.grain <- as.grain(bn.true.fitted)


# Now creating junction trees using compile.grain.
# The trees will be queried to make predictions for S.
junction.tree.own <- compile(bn.fitted.grain)
junction.tree.true <- compile(bn.true.fitted.grain)

# Making predictions using helper-function (separate file)
prediction.own <- predictfunction(junction.tree.own,test,"S")
prediction.true <- predictfunction(junction.tree.true,test,"S")

# Comparing predictions with true values
conf.own <- make.confusion.matrix(test[,"S"],prediction.own)
conf.true <- make.confusion.matrix(test[,"S"],prediction.true)

```

Below the learned sturcture and the true structure is presented for comparision.

```{r}
plot(bn.structure, main="Learned structure")
```


```{r}
plot(bn.true.structure, main="True structure")
```
```{r}
print("Comparing PDAG of learned structure and true structure.")
all.equal(cpdag(bn.true.structure),cpdag(bn.structure))
```


```{r}
print("Confusion matrix using learned structure")
print(conf.own)
print("Confusion matrix using true structure")
print(conf.true)
```

**Finding:** As one can observed, the two confusion matrices are the same even when the structure used for prediction was not. The assumed reason is discussed further in *Task 5*.


# Task 3

*In the previous exercise, S was classified using observations for all the rest of the variables. S should be classified by using only observations for the so-called Markov blanket of S, i.e. its parents plus its children plus the parents of its children minus S itself.*

```{r 3_1, include=FALSE}
# Making predictions using helper-function (separate file)
prediction.own <- predictfunction(junction.tree.own,test,"S", bn.for.markowblanket = bn.structure)
prediction.true <- predictfunction(junction.tree.true,test,"S", bn.for.markowblanket = bn.true.structure)

# Comparing predictions with true values
conf.own <- make.confusion.matrix(test[,"S"],prediction.own)
conf.true <- make.confusion.matrix(test[,"S"],prediction.true)

```

```{r}
print("Markow blanket for learned structure")
print(mb(bn.structure,"S"))
print("Markow blanket for true structure")
print(mb(bn.true.structure,"S"))
```


```{r}
print("Confusion matrix using learned structure")
print(conf.own)
print("Confusion matrix using true structure")
print(conf.true)
```

**Finding:** As one can observed, the same prediction is made which can be expected since the Markow blanket and thereby the nodes used for prediction is the same.

# Task 4

*Repeat the exercise (2) using a naive Bayes classifier, i.e. the predictive variables are independent given the class variable. Model the naive Bayes classifier as a BN. You have to create the BN by hand.*

```{r 4, include=FALSE}

# Learning the structure of the BN.
bn.structure <- model2network("[S][A|S][T|S][L|S][B|S][E|S][X|S][D|S]")

# Learning the parameters.
bn.fitted <- bn.fit(x = bn.structure, data = train, method = "mle")

# Converting to grain obj. to use in compile.grain.
bn.fitted.grain <- as.grain(bn.fitted)

# Now creating junction trees using compile.grain.
# The trees will be queried to make predictions for S.
junction.tree.own <- compile(bn.fitted.grain)

# Making predictions using helper-function (separate file)
prediction.own <- predictfunction(junction.tree.own,test,"S")

# Comparing predictions with true values
conf.own <- make.confusion.matrix(test[,"S"],prediction.own)

```

In the figure below is the Naive Bayes structure for the BN.

```{r}
# plot(bn.structure)
graphviz.plot(bn.structure, layout = "neato")
```

Below is the confusion matrix for the Naive Bayes classifier presented.
```{r}
print(conf.own)
```

# Task 5

*Explain why you obtain the same or different results in the exercises (2-4).*


The reason for the confusion matrices being the same in task 2 and task 3 is because the dependence of “S” is the same in both cases, “L” and “B” (which is the Markow blanket for S). With knowledge about the state of L and B we have full information about "S" and therefore the prediction is the same for the whole network as for the Markow blanket.

The confusion matrix is different in task 4 because of completely different dependency structure, all nodes are only dependent on S and thereby conditionally independent given S (tail-to-tail). We know that this is not the true dependecy structure and cacn therefore expect other predictions.

\newpage

# Appendix for code

## Main code

```{r, code=readLines("lab1-full.R"), echo=TRUE, eval=FALSE}
```

## Helper functions
```{r, code=readLines("helper-functions.R"), echo=TRUE, eval=FALSE}
```
